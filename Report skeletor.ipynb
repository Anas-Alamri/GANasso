{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CS-E4890 Deep Learning 2019 - Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Conditional Deep Convolutional Generative Adversial Network (cDCGAN) for Art Generation* \n",
    "(tai GANasso ym. hyvä otsikko projektille)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of generating new pictures or paintings using deep neural network has been a hot topic and an intriguing challenge for a decade now. In recent years, the implementations have been evolved in a state that neural networks is able to create so believable new images that human cannot recognize if the images are taken with a camera, made by a human or created by neural networks.\n",
    "\n",
    "We wanted to make this implementation, but with a little twist. In our solution, we give 50 thousand images with 4 different labels (flower pictures, portrait paintings, landscape paintins and abstract paintings) to the neural networks. The network then creates new images by using these 4 paintings, but does not mix the labels. For example, if we want to create new flower images, the neural network creates only new flower images and does not mix them with portraits or other labeled images.\n",
    "\n",
    "To create new images out of training images, we used Deep convolutional generate adversial network. To make it differentiating the new image, we used two different conditionality methods so that the network can recognize different labels and does not mix them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Problem and data description\n",
    "- Goal of the project\n",
    "- Methods\n",
    "- What kind of data is used\n",
    "- How we tested and trained different models\n",
    "- Evaluation..?\n",
    "- Muutos\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis/Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Short description about the data (dimensions, amount, where is it from etc.)\n",
    "We used multiple different training data to evaluate our CDCGAN. First, we used Mnist data, that has 50 000 pictures of numbers from 0-9 with 1 dimension (black and white images). As this worked well, we changed to real pictures and paintings which we downloaded from the Kaggle. We downloaded 50 thousand images with 4 different labels: flower pictures, portrait paintings and landscape paintings. All these images are RGB images with 64x64 resolution. Below you can see an example of the these training images.\n",
    "- Preprocessing, example figures, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nCODE\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "CODE: sauli plot 50 images of our own training data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Description of the process and experiments -> tests on MNIST & CIFAR\n",
    "    - First simple models --> simple GAN where there was only linear layers --> simple DCGAN that worked somehow for CIFAR and MNIST --> cDCGAN for MNIST --> conditional GAN for CIFAR --> CDCGAN for our data\n",
    "    - Some results on them?\n",
    "- Description of cDCGAN architecture (Generator, Disc, conditioning, ...)\n",
    "- Specifics of our model (layers, etc...)\n",
    "- Some explanations about the problems in the training (mode collapse, ...)\n",
    "- Experiments with training rates/schedulers, changing layer sizes/number of channels, label smoothening, N number of classes at the time ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nCODE\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "CODE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation criteria (Inception Score?, Fréchet Inception Distance (FID)?, ...)\n",
    "- Latent space interpolation (\"A more sophisticated method for understanding the degree of overfitting in a model is to explore that model’s latentspace by interpolation.\")\n",
    "- L1 distance of closest images/neighbours (\"One  possibility  that  must  be  investigated  is  that  the  AC-GAN has overfit on the training data.  As a first check thatthe network does not memorize the training data, we identify the nearest neighbors of image samples in the training data  measured  by  L1  distance  in  pixel  space  (Figure  8).The nearest neighbors from the training data do not resemble the corresponding samples\" --> Olisi hyvä tulos) [ks. https://arxiv.org/pdf/1610.09585.pdf ]\n",
    "- Gif/animation of the training process\n",
    "- Losses (pitää lisätä, mutta ei oikeastaan kerro mitään hyvyydestä)\n",
    "- Some handpicked examples (best ones)\n",
    "- Some amount of images from each class\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nCODE\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "CODE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How did we do\n",
    "- What went wrong, what kind of problems we had\n",
    "- Comparison to other similar cGANS and their performance\n",
    "- How to improve [mm. https://arxiv.org/pdf/1606.03498.pdf]\n",
    "    - Test different/more sophisticated models: WGAN, WGAN-GP, ACGAN, Stacked GAN ...\n",
    "    - Deeper models\n",
    "    - Different hyperparameters\n",
    "    - Balancing the training\n",
    "        - Experience replay\n",
    "        - Minibatch discrimination\n",
    "        - Label smoothening\n",
    "   - ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] ... \n",
    "\n",
    "[2] ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix ?? (katotaan jos tarvii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ehkä testiversioita\n",
    "- Koko koodi yhtenä pötkönä ?\n",
    "- Datacombiner\n",
    "- muuta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kommetteja:\n",
    "\n",
    "- Koodi appendixiin kokonaisuudessaan ja kommentoituna vai osittain raportin sekaan kuten MLBP:ssä?\n",
    "- Täytyy muistaa rapsaa kirjoittaessa feedback kriteerit (https://mycourses.aalto.fi/pluginfile.php/929341/mod_resource/content/3/project_work_evaluation_form.txt)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

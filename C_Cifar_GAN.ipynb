{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1113,
     "status": "ok",
     "timestamp": 1556112357167,
     "user": {
      "displayName": "Sauli Sjögren",
      "photoUrl": "",
      "userId": "12974090036060883229"
     },
     "user_tz": -180
    },
    "id": "krZ_s2T8AyGP",
    "outputId": "f7d32294-e2bb-4b95-ee33-d27e47044bfc"
   },
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from matplotlib.pyplot import imshow, imsave\n",
    "\n",
    "# Set random seem for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1556112357172,
     "user": {
      "displayName": "Sauli Sjögren",
      "photoUrl": "",
      "userId": "12974090036060883229"
     },
     "user_tz": -180
    },
    "id": "gFpazwrKvrRU",
    "outputId": "51395031-7239-498d-c0a1-eba08c278321"
   },
   "outputs": [],
   "source": [
    "# This cell is only for Google Colaboratory\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "#\n",
    "path1 = \"train_images\" # Tähän osoitteeseen kuvat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5o86TewfDqHr"
   },
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"Art/Uusi_Kansio\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 100\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3 # with mnist 1, other 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "max_epoch = 100 # need more than 20 epochs for training generator\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# Number of labels\n",
    "num_labels = 2 # we will use 4, CIFAR and MNIST has 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1843,
     "status": "ok",
     "timestamp": 1556112362115,
     "user": {
      "displayName": "Sauli Sjögren",
      "photoUrl": "",
      "userId": "12974090036060883229"
     },
     "user_tz": -180
    },
    "id": "aY896uDQAyG5",
    "outputId": "4039f4b0-d15f-4fba-de08-b4cafaaaf54e"
   },
   "outputs": [],
   "source": [
    "# Define which device you use for calculation. If you can use cuda, this will automatically use it. Otherwise cpu is automatically used.\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jC0W-gpnqQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "#transform=torchvision.transforms.Compose([\n",
    " #                                torchvision.transforms.Resize(image_size),\n",
    "  #                               torchvision.transforms.ToTensor(),\n",
    "   #                              torchvision.transforms.Normalize(\n",
    "    #                             (0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "#dataset =  torchvision.datasets.CIFAR10('/files/', train=True, download=True, transform = transform)\n",
    "\n",
    "#data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#real_batch = next(iter(data_loader))\n",
    "#plt.figure(figsize=(8,8))\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(\"Training Images\")\n",
    "#plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(DEVICE)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9VWewv3ZvJz"
   },
   "outputs": [],
   "source": [
    "dataroot = []\n",
    "dataset = []\n",
    "# Create new dataset from images\n",
    "for i in range(1,num_labels + 1):\n",
    "    dataset.append(dset.ImageFolder(root=F\"./Dog_images/Label{i}\",\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])))\n",
    "\n",
    "# Create labels for our dataset\n",
    "# Labels are in i\n",
    "for i in range(len(dataset)):\n",
    "    for j in range(len(dataset[i])):\n",
    "        dataset[i].samples[j] = (dataset[i].samples[j][0],i)\n",
    "        \n",
    "# Combine all the datasets\n",
    "newdataset = torch.utils.data.ConcatDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88614,
     "status": "ok",
     "timestamp": 1556112456094,
     "user": {
      "displayName": "Sauli Sjögren",
      "photoUrl": "",
      "userId": "12974090036060883229"
     },
     "user_tz": -180
    },
    "id": "Da03iRyCZ27F",
    "outputId": "ddb878a9-722d-4b69-879b-fab3f97728b7"
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(newdataset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "#DEVICE = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch,labels = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch.to(DEVICE)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1b318tFHAyHT"
   },
   "outputs": [],
   "source": [
    "def get_sample_image(G, n_noise=100):\n",
    "    \"\"\"\n",
    "        save sample 100 images\n",
    "    \"\"\"\n",
    "    img = np.zeros([image_size * 10, image_size * 10])\n",
    "    for j in range(10):\n",
    "        c = torch.zeros([10, 10]).to(DEVICE)\n",
    "        c[:, j] = 1\n",
    "        z = torch.randn(10, n_noise).to(DEVICE)\n",
    "        y_hat = G(z,c).view(10, image_size, image_size)\n",
    "        result = y_hat.cpu().data.numpy()\n",
    "        img[j*image_size:(j+1)*image_size] = np.concatenate([x for x in result], axis=-1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEbGlgA6AyHb"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Discriminator for MNIST\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel=1, input_size=784, condition_size=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(nc, ndf,4,2,1,bias=False)\n",
    "        \n",
    "        # first parameter is number of classes, condition_size is the same as number of classes\n",
    "        self.convlabel = nn.Conv2d(condition_size, ndf,4,2,1,bias=False)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(ndf * 2,ndf * 4, 4, 2, 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv3 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv4 = nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf * 16)\n",
    "        self.conv5 = nn.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False)\n",
    "\n",
    "        self.act = nn.LeakyReLU(0.2,inplace=True)\n",
    "        self.out = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            classname = m.__class__.__name__\n",
    "            if classname.find('Conv') != -1:\n",
    "                torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            elif classname.find('BatchNorm') != -1:\n",
    "                torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "                torch.nn.init.constant_(m.bias.data, 0)\n",
    "                \n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        \n",
    "        x = self.act(self.conv1(x))\n",
    "        y = self.act(self.convlabel(y))\n",
    "        x = torch.cat([x,y],1)\n",
    "        x = self.act(self.bn1(self.conv2(x)))\n",
    "        x = self.act(self.bn2(self.conv3(x)))\n",
    "        x = self.act(self.bn3(self.conv4(x)))\n",
    "        x = self.conv5(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmfBgT_zAyHl"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Generator for MNIST\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size = 100, condition_size=10):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose2d(input_size, ngf * 8, 4, 1, 0,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(ngf*8)\n",
    "        \n",
    "        \n",
    "        # first parameter is number of classes\n",
    "        self.convlabel = nn.ConvTranspose2d(condition_size, ngf * 8, 4, 1, 0,bias=False)\n",
    "        self.bn1_1 = nn.BatchNorm2d(ngf * 8)\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.ConvTranspose2d(ngf * 16,ngf * 8, 4, 2, 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf * 8)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(ngf * 8,ngf * 4, 4, 2, 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf * 4)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(ngf * 4,ngf * 2, 4, 2, 1, bias = False)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf * 2)\n",
    "        \n",
    "        self.conv5 = nn.ConvTranspose2d(ngf*2, nc, 4, 2, 1, bias = False)\n",
    "        self.out = nn.Tanh()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            classname = m.__class__.__name__\n",
    "            if classname.find('Conv') != -1:\n",
    "                torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            elif classname.find('BatchNorm') != -1:\n",
    "                torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "                torch.nn.init.constant_(m.bias.data, 0)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        x = self.act(self.bn1(self.conv1(x)))\n",
    "        y = self.act(self.bn1_1(self.convlabel(y)))\n",
    "        x = torch.cat([x,y],1)\n",
    "        x = self.act(self.bn2(self.conv2(x)))\n",
    "        x = self.act(self.bn3(self.conv3(x)))\n",
    "        x = self.act(self.bn4(self.conv4(x)))\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1556112466914,
     "user": {
      "displayName": "Sauli Sjögren",
      "photoUrl": "",
      "userId": "12974090036060883229"
     },
     "user_tz": -180
    },
    "id": "yv4vwx3YAyHy",
    "outputId": "3611d312-48af-4d84-e7ef-11f3c1751c67"
   },
   "outputs": [],
   "source": [
    "D = Discriminator(condition_size = num_labels).to(DEVICE)\n",
    "G = Generator(condition_size=num_labels).to(DEVICE)\n",
    "# D.load_state_dict('D_dc.pkl')\n",
    "# G.load_state_dict('G_dc.pkl')\n",
    "\n",
    "# Initialize discriminator and Generator weights\n",
    "#D.apply(weight_init)\n",
    "#G.apply(weight_init)\n",
    "\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "\n",
    "print(ngf*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWe1eqkRAyI2"
   },
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn((batch_size, 100, 1, 1))\n",
    "fixed_noise = Variable(fixed_noise.to(DEVICE))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QXPmgEXAyJB"
   },
   "outputs": [],
   "source": [
    "# Initialize stuff before training\n",
    "step = 0\n",
    "n_critic = 1 # for training more k steps about Discriminator\n",
    "n_noise = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4Xd-mMJAyJL"
   },
   "outputs": [],
   "source": [
    "D_labels = torch.ones([batch_size, 1]).to(DEVICE) # Discriminator Label to real\n",
    "D_fakes = torch.zeros([batch_size, 1]).to(DEVICE) # Discriminator Label to fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98679,
     "status": "ok",
     "timestamp": 1556113363592,
     "user": {
      "displayName": "Sauli Sjögren",
      "photoUrl": "",
      "userId": "12974090036060883229"
     },
     "user_tz": -180
    },
    "id": "CApcMEraAyJV",
    "outputId": "64b90235-4054-43b9-d800-b1e3ad46a34f"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "# Create arrays for Generator and Discriminator losses\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "\n",
    "fixed_y = torch.zeros(num_labels, 1)\n",
    "y_label = torch.zeros(batch_size, num_labels)\n",
    "\n",
    "# Creates onehot array, that is diagonal matrix in tensor from.\n",
    "onehot = torch.zeros(num_labels, num_labels)\n",
    "onehot = onehot.scatter_(1, torch.LongTensor([range(num_labels)]).view(num_labels,1), 1).view(num_labels, num_labels, 1, 1)\n",
    "\n",
    "# Creates fill that makes image size layer with ones for each label\n",
    "fill = torch.zeros([num_labels, num_labels, image_size, image_size]).to(DEVICE)\n",
    "for i in range(num_labels):\n",
    "    fill[i, i, :, :] = 1\n",
    "\n",
    "\n",
    "\n",
    "# Fixed Y labels for evaluation\n",
    "y_0 = torch.full((batch_size//num_labels, 1), 0).type(torch.LongTensor).squeeze()\n",
    "y_fixed_labels = torch.zeros(batch_size, num_labels)\n",
    "\n",
    "for i in range(1,num_labels):\n",
    "    desired_label = i\n",
    "    y_fixed = torch.full((batch_size//num_labels, 1), desired_label).type(torch.LongTensor).squeeze()\n",
    "\n",
    "    y_0 = torch.cat((y_0, y_fixed), 0)\n",
    "\n",
    "y_fixed_labels = onehot[y_0]\n",
    "y_fixed_labels= Variable(y_fixed_labels.cuda())\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (images, labels) in enumerate(dataloader):\n",
    "\n",
    "        # Training Discriminator\n",
    "        \n",
    "        # Use print(labels.shape) to check how large batch size should be\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        \n",
    "        y_fill = fill[labels]\n",
    "        \n",
    "        x = images.to(DEVICE)\n",
    "        y = y_fill\n",
    "        x_outputs = D(x, y)\n",
    "        x_outputs = x_outputs.view(-1,1)\n",
    "        D_x_loss = criterion(x_outputs, D_labels)\n",
    "        \n",
    "        # Fake data:\n",
    "        \n",
    "        z = torch.randn((batch_size, 100, 1, 1))\n",
    "        y_rand = (torch.rand(batch_size, 1) * num_labels).type(torch.LongTensor).squeeze()\n",
    "        y_label = onehot[y_rand]\n",
    "        y_fill = fill[y_rand]\n",
    "        z = Variable(z.to(DEVICE))\n",
    "        y_label = Variable(y_label.to(DEVICE))\n",
    "        y_fill =  Variable(y_fill.to(DEVICE))\n",
    "        \n",
    "        fake_images = G(z, y_label)\n",
    "        \n",
    "        fake_outputs = D(fake_images, y_fill)\n",
    "        fake_outputs = fake_outputs.view(-1,1)\n",
    "        D_z_loss = criterion(fake_outputs, D_fakes)\n",
    "         \n",
    "        D_loss = D_x_loss + D_z_loss\n",
    "        \n",
    "        D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "        \n",
    "        if step % n_critic == 0:\n",
    "            # Training Generator\n",
    "            \n",
    "            z = torch.randn((batch_size, 100, 1, 1))\n",
    "            y_rand = (torch.rand(batch_size, 1) * num_labels).type(torch.LongTensor).squeeze()\n",
    "            y_label = onehot[y_rand]\n",
    "            y_fill = fill[y_rand]\n",
    "            z = Variable(z.to(DEVICE))\n",
    "            y_label = Variable(y_label.to(DEVICE))\n",
    "            y_fill =  Variable(y_fill.to(DEVICE))\n",
    "            \n",
    "            fake_images = G(z,y_label)\n",
    "            \n",
    "            fake_outputs = D(fake_images, y_fill)\n",
    "            fake_outputs = fake_outputs.view(-1,1)\n",
    "            G_loss = criterion(fake_outputs, D_labels)\n",
    "            G.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_opt.step()       \n",
    "        if step % 500 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, max_epoch, step, D_loss.item(), G_loss.item()))\n",
    "            # Output training stats\n",
    "        \n",
    "\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(G_loss.item())\n",
    "            D_losses.append(D_loss.item())\n",
    "\n",
    "    #if step % 1000 == 0:\n",
    "            #G.eval()\n",
    "            #img = get_sample_image(G, n_noise)\n",
    "            #imsave('samples/{}_step{}.jpg'.format(MODEL_NAME, str(step).zfill(3)), img, cmap='gray')\n",
    "            #G.train()\n",
    "            \n",
    "        step += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    if (epoch % 1 == 0):\n",
    "        print(\"Figure number: \", epoch+1)\n",
    "        # generation to image\n",
    "        G.eval()\n",
    "\n",
    "        # Create labels from 0 to 9 (tensor is 100 long)\n",
    "       \n",
    "        # save image\n",
    "        \n",
    "        #torch.save(netG.state_dict(), os.path.join(path2, 'G--{}.ckpt'.format(epoch+1)))\n",
    "        #torch.save(netD.state_dict(), os.path.join(path3, 'D--{}.ckpt'.format(epoch+1)))\n",
    "        with torch.no_grad():\n",
    "            fake_images = G(fixed_noise,y_fixed_labels).detach().cpu()\n",
    "            #plt.figure(figsize=(8,8))\n",
    "            #plt.axis(\"off\")\n",
    "            #plt.title(\"Training Images\")\n",
    "         #plt.imshow(np.transpose(vutils.make_grid(fake_images.to(DEVICE)[:64], padding=5,pad_value = 1, normalize=True).cpu(),(1,2,0)))\n",
    "        vutils.save_image((fake_images.data), os.path.join(path1, 'fake_images-{}.png'.format(epoch+1)), nrow = 10, normalize=True)\n",
    "        G.train()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4757,
     "status": "ok",
     "timestamp": 1556113396626,
     "user": {
      "displayName": "Sauli Sjögren",
      "photoUrl": "",
      "userId": "12974090036060883229"
     },
     "user_tz": -180
    },
    "id": "ClRtye-1AyJh",
    "outputId": "0b42cc8d-af1d-4478-92d2-b9528832e624",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generation to image\n",
    "G.eval()\n",
    "\n",
    "# put here the desired label you want to be seen\n",
    "desired_label = 2\n",
    "\n",
    "y_rand = torch.full((batch_size, 1), desired_label).type(torch.LongTensor).squeeze()\n",
    "y_label = onehot[y_rand]\n",
    "#y_label = onehot.scatter_(1, torch.LongTensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).view(10,1), 1).view(10, 10, 1, 1)\n",
    "z = Variable(z.cuda())\n",
    "y_label = Variable(y_label.cuda())\n",
    "\n",
    "\n",
    "# Generate images using fixed noise and specific labels. For example \"generate fake landscape images\"\n",
    "with torch.no_grad():\n",
    "    fake_images = G(fixed_noise,y_label).detach().cpu()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Plot figures of specific labels    \n",
    "    \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(fake_images.to(DEVICE)[:64], padding=5,pad_value = 1, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "\n",
    "# Plot each image separately.\n",
    "\n",
    "#print(fake_images[0][0].shape)\n",
    "#for i in range(20):\n",
    " #   plt.imshow(fake_images[i][0])\n",
    "  #  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9lDg_o9DAyJq"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, file_name='checkpoint.pth.tar'):\n",
    "    torch.save(state, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iEGpiy8AyJz"
   },
   "outputs": [],
   "source": [
    "# Saving params.\n",
    "# torch.save(D.state_dict(), 'D_c.pkl')\n",
    "# torch.save(G.state_dict(), 'G_c.pkl')\n",
    "save_checkpoint({'epoch': epoch + 1, 'state_dict':D.state_dict(), 'optimizer' : D_opt.state_dict()}, 'D_dc.pth.tar')\n",
    "save_checkpoint({'epoch': epoch + 1, 'state_dict':G.state_dict(), 'optimizer' : G_opt.state_dict()}, 'G_dc.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjlyknuaBgdr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AultrzIoBiEb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C_Cifar_GAN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
